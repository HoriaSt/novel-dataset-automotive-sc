{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c265f2a4-c31c-499a-8023-09673f529a82",
   "metadata": {},
   "source": [
    "## Inferring Results with the OpenAI GPT 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3d8d26-8b40-42ef-bb68-9dc3a0cfac5a",
   "metadata": {},
   "source": [
    "### Prerequisits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "375da5c6-1073-4ffe-91b7-cc12b69f4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import openai\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e05015-df32-4dfa-a811-ac2c07814d38",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "98edfe12-269f-4019-a73c-dacaaa00ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"<article> {text} </article>\n",
    "<company A> {comp_initial} </company A>\n",
    "<company B> {comp_new} </comapny B>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "18093596-1bff-49a2-86dd-711c5dfabad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = \"\"\" You are a classifier that analyzes a given excerpt of a news article (delimited with XML tags) and extracts the relationship between two companies: company A and B (delimited with XML tags). The answer will only be based on the information provided in the excerpt. You reply with only one word, which labels the type of interaction between the two companies. \n",
    "\n",
    "The labels you can output are:\n",
    "- \"supplier\": if company A supplies products to company B and is part of company A's supply chain.\n",
    "- \"buyer\": if company A is buying any parts in its production from company B.\n",
    "- \"merger\": if companies A and B are involved in a mergers & acquisitions transaction.\n",
    "- \"partnership\": if company A and company B are collaborating in any other way\n",
    "- \"nothing\": if there is no connection between company A and company B from the excerpt (for example they appear together in an enumeration)\n",
    "\n",
    "Few shot examples:\n",
    "<examples>\n",
    "<user>\n",
    "<article> General Motors' (GM) GM Ventures joined in an $11 million Series A funding round in North Carolina lithium-metal battery maker Soelect </article>\n",
    "<company A> Soelect </company A> <company B> GM </comapny B>\n",
    "</user>\n",
    "<assistant> merger </assistant>\n",
    "<user>\n",
    "<article> Ford Motor Company and Changan Automobile recently announced their commitment to strengthening their strategic cooperation and will innovate the business models and increase cooperation efficiency. </article>\n",
    "<company A> Ford Motor </company A> <company B> Changan Automobile </comapny B>\n",
    "</user>\n",
    "<assistant> partnership </assistant>\n",
    "<user>\n",
    "<article> The South Korean battery maker signed an agreement with Akasol, the leading manufacturer of high-performance lithium-ion battery systems in Frankfurt for two orders for global commercial vehicles. Under the agreement, Samsung SDI will supply its battery cells and modules to the German. </article>\n",
    "<company A> Akasol </company A> <company B> Samsung SDI </comapny B>\n",
    "</user>\n",
    "<assistant> buyer </assistant>\n",
    "<user>\n",
    "<article> Key Players Profiled in the study includes:- Cabot,Cytec Solvay,HEG,Hexcel,Mersen S.A,Mitsubishi Rayon,Morgan Advanced Materials,SEC Carbon,IBIDEN,GrafTechCataloging the Competitive Terrain of the Carbon & Graphite Market </article>\n",
    "<company A> Morgan Advanced Materials </company A> <company B> Mitsubishi </comapny B>\n",
    "</user>\n",
    "<assistant> nothing </assistant>\n",
    "</examples>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e513ff-99ee-4d17-afb0-3d628b6d8792",
   "metadata": {},
   "source": [
    "#### Obtaining a list of Automotive OEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b6813efb-5fe8-4fe7-bda4-8d26867240e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparql_dataframe\n",
    "\n",
    "# Define the SPARQL endpoint\n",
    "endpoint = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "# Define the SPARQL query to obtain OEM car manufacturers\n",
    "query = \"\"\"\n",
    "SELECT ?manufacturer ?manufacturerLabel ?revenue WHERE {\n",
    "  ?manufacturer wdt:P31 wd:Q786820;  # Instance of car manufacturer\n",
    "                wdt:P2139 ?revenue.   # Revenue property\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
    "}\n",
    "ORDER BY DESC(?revenue)\n",
    "LIMIT 300\n",
    "\"\"\"\n",
    "\n",
    "#  wdt:P31 - Instance of car manufacturer, and Q786820 of car label\n",
    "# wdt:P2139 - Revenue Property\n",
    "# Run the query and convert the result to a pandas DataFrame\n",
    "df = sparql_dataframe.get(endpoint, query, post=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7087fe7a-fc1c-4c78-8359-84dd7d330bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#manually filtering the car manufacturers obtained from Wikidata\n",
    "list_car_manufacturers = [\n",
    "    'Volkswagen', 'VW', 'VW Group', 'Audi', 'Skoda', 'Seat', 'Cupra', 'KTM', 'Puch', \n",
    "    'Nova', 'Nova Bus', 'BRP', 'Campagna', 'Lion Electric', 'BYD', 'Geely', 'Great Wall', 'NIO', \n",
    "    'Xpeng', 'SAIC', 'Changan', 'FAW', 'Hongqi', 'Trumpchi', 'GAC', 'Chery', 'Li Auto', 'Rimac', \n",
    "    'Tatra', 'Zenvo', 'Electric Raceabout', 'Aixam', 'Alpine', 'DS', 'Citroen', 'CitroÃ«n', 'Bugatti', \n",
    "    'Peugeot', 'PSA', 'Renault', 'Renault Trucks', 'Alpina', 'BMW', 'Daimler', 'Mercedes', \n",
    "    'Mercedes-Benz', 'Opel', 'RUF', 'Porsche', 'Smart', 'Maybach', 'Ashok Leyland', 'Bajaj', \n",
    "    'Eicher', 'Hero MotoCorp', 'Mahindra', 'Maruti Suzuki', 'SML Isuzu', 'Tata', 'Tata Motors', \n",
    "    'TVS', 'Atul Auto', 'Hindustan', 'ICML', 'Omega Seiki Mobility', 'KAL', 'Esemka', 'Pindad', \n",
    "    'Abarth', 'Alfa Romeo', 'Ferrari', 'Fiat', 'Stellantis', 'Lancia', 'Lamborghini', 'Maserati', \n",
    "    'Pagani', 'Piaggio', 'Acura', 'Daihatsu', 'Honda', 'Infiniti', 'Isuzu', 'Lexus', 'Mazda', \n",
    "    'Mitsubishi', 'Mitsubishi Motors', 'Nissan', 'Subaru', 'Suzuki', 'Toyota', 'Spyker', 'Solaris', \n",
    "    'Arrinera', 'Dacia', 'Aurus', 'GAZ', 'Daewoo', 'Hyundai', 'KIA', 'Koenigsegg', 'Polestar', \n",
    "    'Volvo', 'Volvo Cars', 'Saab', 'Otokar', 'Aston Martin', 'Bentley', 'Jaguar', 'Lagonda', \n",
    "    'Land Rover', 'Range Rover', 'Lotus', 'MINI', 'Morgan', 'Rolls-Royce', 'Rolls Royce', 'McLaren', \n",
    "    'TVR', 'Vauxhall', 'Ford', 'GM', 'Chevrolet', 'Cadillac', 'Dodge', 'Jeep', 'Buick', 'GMC', \n",
    "    'Chrysler', 'Lincoln', 'Hennessey', 'Shelby', 'SRT', 'Tesla', 'Rivian', 'Lucid Motors', \n",
    "    'Fisker', 'Faraday', 'Nikola Motor', 'Canoo', 'BrightDrop', 'Polaris', 'Aptera'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fafc9eb-4d8a-4991-978a-aa6b36478b65",
   "metadata": {},
   "source": [
    "#### Function for selecting only OEMs from the companies identified with NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4639e116-7f22-4977-a7f4-70b8e4c5eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_oems (data, list_car_manufacturers):\n",
    "\n",
    "    '''\n",
    "        This function takes as input a dataframe parsed from the\n",
    "        ner_stanza_preproc notebook and the list of car manufacturers \n",
    "        retrieved from WikiData and afterwards manually cleaned. Using\n",
    "        these two, it makes sure to only keep from the named entities\n",
    "        those whose names hint towards an OEM. The function returns the\n",
    "        dataset filtered for only the rows where the retrieved named entity\n",
    "        is an OEM (the NAATBatt companies stay as they are).\n",
    "    '''\n",
    "    \n",
    "    import re\n",
    "    #some values are NAs and we cannot use them\n",
    "    data.dropna(axis = 0, inplace = True)\n",
    "    data['new_company'] = data['new_company'].astype(str)\n",
    "    \n",
    "    #we will match based on lower characters\n",
    "    list_car_manufacturers = [producer.lower() for producer in list_car_manufacturers]\n",
    "    new_company_news = data.new_company.apply(lambda x: x.lower())\n",
    "    \n",
    "    # Create a regex pattern for the list of car manufacturers for joining\n",
    "    pattern = '|'.join([f'\\\\b{re.escape(manufacturer)}\\\\b' for manufacturer in list_car_manufacturers])\n",
    "    \n",
    "    # Filter the DataFrame for partial matches\n",
    "    filtered_indices = new_company_news[new_company_news.str.contains(pattern, case=False, na=False)].index\n",
    "    \n",
    "    #filtering dataframe based on indices to preserve captialization\n",
    "    data_filtered = data.loc[filtered_indices]\n",
    "    \n",
    "    #removing new_company names longer than 40 characters - as the list has max 20 and makes no sense to include false results\n",
    "    data_filtered = data_filtered[data_filtered['new_company'].str.len() < 40]\n",
    "\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b611af6-809d-4bc7-86c2-de2d8785569a",
   "metadata": {},
   "source": [
    "### Main code snippet for creating the prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d57a94-5404-4e26-aab4-baa2a6907b77",
   "metadata": {},
   "source": [
    "#### Filtering to only keep NAATBatt companies and automotive OEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e184276a-d321-4716-baad-9208bead7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = 'data/'\n",
    "\n",
    "#pasting results in a new df\n",
    "prompt_raw_data = {\n",
    "    'text': [],\n",
    "    'initial_company': [],\n",
    "    'new_company': []\n",
    "}\n",
    "\n",
    "# Create an empty DataFrame with the same structure\n",
    "prompt_raw_data = pd.DataFrame(prompt_raw_data)\n",
    "\n",
    "#iterating over files\n",
    "for subfolder in os.listdir(data_folder_path):\n",
    "    subfolder_path = os.path.join(data_folder_path, subfolder)\n",
    "\n",
    "    # Check if it is a directory\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Find the CSV file ending with ews.csv in the current subfolder\n",
    "        csv_files = glob.glob(os.path.join(subfolder_path, '*_prompt_ready.csv'))\n",
    "        \n",
    "        # There should be exactly one CSV file per subfolder as per the given structure\n",
    "        if csv_files:\n",
    "            csv_file_path = csv_files[0]  # Get the path of the CSV file\n",
    "            data = pd.read_csv(csv_file_path, \n",
    "                               sep = ',',\n",
    "                               usecols=['text','initial_company','new_company'],\n",
    "                               on_bad_lines = 'skip',\n",
    "                               engine = 'pyarrow')\n",
    "\n",
    "            #filtering the oems from the predefined list\n",
    "            filtered_oems = select_oems(data, list_car_manufacturers)\n",
    "            \n",
    "            #appedning to new dataframe which will include all companies\n",
    "            prompt_raw_data = pd.concat([prompt_raw_data, filtered_oems], ignore_index=True)\n",
    "\n",
    "#these create a lot of self loops so we remove them\n",
    "filter_strings = ['ford', 'morgan', 'rivian']\n",
    "prompt_raw_data = prompt_raw_data[~prompt_raw_data.apply(lambda row: any(s in row['initial_company'].lower() and s in row['new_company'].lower() for s in filter_strings), axis=1)]\n",
    "\n",
    "#parse results\n",
    "prompt_raw_data.to_csv('oem_raw_prompt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfd834a-4ca5-445c-a261-4154e96c5d6b",
   "metadata": {},
   "source": [
    "#### Creating the Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "641ca524-d102-45bc-9649-41fc4d73e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the parsed intermediary results\n",
    "prompt_raw_data = pd.read_csv('oem_raw_prompt.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "785763e8-aadc-4ac6-9e4d-8381bedb052f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[180], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m url_pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS*https?://\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS+|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS*www\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS+)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 11\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_pattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt_template\u001b[38;5;241m.\u001b[39mformat(text \u001b[38;5;241m=\u001b[39m text,\n\u001b[1;32m     14\u001b[0m                                 comp_initial \u001b[38;5;241m=\u001b[39m comp,\n\u001b[1;32m     15\u001b[0m                                 comp_new \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_company\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m list_prompts\u001b[38;5;241m.\u001b[39mappend((comp, prompt, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_company\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/re/__init__.py:185\u001b[0m, in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#temporary list of prompts\n",
    "list_prompts = []\n",
    "\n",
    "for index,row in prompt_raw_data.iterrows():\n",
    "    #cleaning the company name\n",
    "    comp = row['initial_company'].replace('_',' ').replace('  ','').replace('+','')\n",
    "\n",
    "    #cleaning the text\n",
    "    text = row['text'].replace('\\n','').replace('`','')\n",
    "    url_pattern = r'(\\S*https?://\\S+|\\S*www\\.\\S+)'\n",
    "    text = re.sub(url_pattern, '', text)\n",
    "\n",
    "    #adding the companies in the prompts\n",
    "    prompt = prompt_template.format(text = text,\n",
    "                                    comp_initial = comp,\n",
    "                                    comp_new = row['new_company'])\n",
    "\n",
    "    #adding in the temporary list of prompts\n",
    "    list_prompts.append((comp, prompt, row['new_company']))\n",
    "\n",
    "#parsing the prompts lists to csv\n",
    "prompts = pd.DataFrame(list_prompts, columns = ['company', 'prompt', 'connection'])\n",
    "prompts['tokens'] = prompts.prompt.apply(count_tokens)\n",
    "prompts.to_csv('oem_prompts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4776ac-724a-4854-83f0-b8eb26b78169",
   "metadata": {},
   "source": [
    "### Running the Inference with GPT 3.5 turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5dce86f2-7a1a-4e3c-a032-367607f2b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = pd.read_csv('oem_prompts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c2607479-40d7-4d38-8fb2-10a07be702dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the token\n",
    "client = openai.OpenAI(api_key=\"OPENAI_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3d5ae5d9-622d-456a-b137-82e6bad6be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_openai(prompt):\n",
    "    '''\n",
    "         This function calls the OpenAI API using the token\n",
    "         and the prompt, and returns the answer\n",
    "    '''\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.1,\n",
    "        max_tokens = 50,\n",
    "        top_p = 1,\n",
    "        frequency_penalty = 2,\n",
    "        presence_penalty = 0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_instruction\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08738e25-e433-402b-beba-57ca088bfb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#for parsing the results\n",
    "results = {\n",
    "    'company':[],\n",
    "    'prompt':[],\n",
    "    'connection':[],\n",
    "    'tokens':[],\n",
    "    'result':[]\n",
    "}\n",
    "\n",
    "#looping through the list of prompts to get streaming answers from all of them\n",
    "for i, row in prompts.iterrows():\n",
    "    company_a = row.company\n",
    "    prompt = row.prompt\n",
    "    company_b = row.connection\n",
    "    tokens = row.tokens\n",
    "    try:\n",
    "        result = run_openai(prompt)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "    results['company'].append(company_a)\n",
    "    results['prompt'].append(prompt)\n",
    "    results['connection'].append(company_b)\n",
    "    results['tokens'].append(tokens)\n",
    "    results['result'].append(result)\n",
    "    \n",
    "    if i % 1500 == 0:\n",
    "        results_1 = pd.DataFrame(results)\n",
    "        results_1.to_csv('final_results/'+str(i)+'-streaming.csv')\n",
    "        results = {\n",
    "            'company':[],\n",
    "            'prompt':[],\n",
    "            'connection':[],\n",
    "            'tokens':[],\n",
    "            'result':[]\n",
    "        }\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aacf00c-3a97-4e1d-8180-52f41e5ab7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
